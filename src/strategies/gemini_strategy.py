# src/strategies/gemini_strategy.py

import os
import json
import hashlib
import time
from dotenv import load_dotenv
from google import genai
from pydantic import BaseModel, Field
from typing import Literal, Tuple, Dict, Optional
from datetime import datetime, timezone
import pandas as pd
from alpaca.data.timeframe import TimeFrame, TimeFrameUnit

# å¯¼å…¥æ•°æ®è·å–å™¨ã€ç¼“å­˜å’ŒåŸºç±»
from src.data_fetcher.alpaca_data_fetcher import AlpacaDataFetcher
from src.cache.trading_cache import TradingCache
from src.strategies.base_strategy import BaseStrategy # å¯¼å…¥åŸºç±»

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# Gemini æ¨¡å‹é…ç½®
GEMINI_MODEL = "gemini-2.0-flash-exp"  # ä½¿ç”¨æœ€æ–°çš„ Flash æ¨¡å‹


class TradingSignal(BaseModel):
    """äº¤æ˜“ä¿¡å·æ¨¡å‹ - ç”¨äºå¼ºåˆ¶ Gemini è¾“å‡ºç»“æ„åŒ–æ•°æ®"""
    signal: Literal["BUY", "SELL", "HOLD"] = Field(
        description="åŸºäºæŠ€æœ¯åˆ†æå’Œå¸‚åœºæ•°æ®ï¼Œç»™å‡ºä¹°å…¥ã€å–å‡ºæˆ–è§‚æœ›çš„äº¤æ˜“ä¿¡å·ã€‚"
    )
    confidence_score: int = Field(
        ..., 
        ge=1, 
        le=10,
        description="å¯¹ä¿¡å·çš„è‡ªä¿¡ç¨‹åº¦è¯„åˆ†ï¼Œ1ä¸ºæœ€ä½ï¼Œ10ä¸ºæœ€é«˜ã€‚"
    )
    reason: str = Field(
        description="ç®€è¦è¯´æ˜ç»™å‡ºæ­¤ä¿¡å·çš„åŸå› ï¼Œå¿…é¡»åŸºäºæä¾›çš„æŠ€æœ¯æŒ‡æ ‡å’Œä»·æ ¼æ•°æ®ã€‚"
    )


class GeminiStrategy(BaseStrategy): # ç»§æ‰¿ BaseStrategy
    """
    åŸºäº Gemini AI çš„äº¤æ˜“ç­–ç•¥ã€‚
    
    ç‰¹ç‚¹ï¼š
    1. ä½¿ç”¨ Gemini API åˆ†ææŠ€æœ¯æŒ‡æ ‡å’Œä»·æ ¼èµ°åŠ¿
    2. æ”¯æŒç¼“å­˜ä»¥å‡å°‘ API è°ƒç”¨å’Œæˆæœ¬
    3. å¯è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ï¼ˆtrading personaï¼‰
    4. çµæ´»çš„å‚æ•°é…ç½®
    """
    
    # é»˜è®¤ç³»ç»Ÿæç¤ºè¯
    DEFAULT_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„é‡åŒ–äº¤æ˜“å‘˜ï¼Œä¸“æ³¨äºçŸ­æœŸäº¤æ˜“å’ŒæŠ€æœ¯åˆ†æã€‚

ä½ çš„ä»»åŠ¡æ˜¯åˆ†ææä¾›çš„è‚¡ç¥¨æŠ€æœ¯æŒ‡æ ‡æ•°æ®ï¼ˆåŒ…æ‹¬ä»·æ ¼ã€å¸ƒæ—å¸¦ã€RSIç­‰ï¼‰ï¼Œå¹¶ç»™å‡ºæ˜ç¡®çš„äº¤æ˜“å»ºè®®ã€‚

åˆ†æè¦ç‚¹ï¼š
1. **è¶‹åŠ¿åˆ¤æ–­**ï¼šè§‚å¯Ÿä»·æ ¼ç›¸å¯¹äºç§»åŠ¨å¹³å‡çº¿(SMA)çš„ä½ç½®
2. **å¸ƒæ—å¸¦åˆ†æ**ï¼š
   - ä»·æ ¼è§¦åŠä¸‹è½¨å¯èƒ½æ˜¯ä¹°å…¥æœºä¼šï¼ˆè¶…å–ï¼‰
   - ä»·æ ¼è§¦åŠä¸Šè½¨å¯èƒ½æ˜¯å–å‡ºæœºä¼šï¼ˆè¶…ä¹°ï¼‰
3. **RSIæŒ‡æ ‡**ï¼š
   - RSI < 30 è¡¨ç¤ºè¶…å–ï¼Œå¯èƒ½åå¼¹
   - RSI > 70 è¡¨ç¤ºè¶…ä¹°ï¼Œå¯èƒ½å›è°ƒ
   - RSI åœ¨ 30-70 ä¹‹é—´ä¸ºä¸­æ€§åŒºåŸŸ
4. **æˆäº¤é‡**ï¼šå¼‚å¸¸æ”¾é‡å¯èƒ½é¢„ç¤ºè¶‹åŠ¿å˜åŒ–

äº¤æ˜“åŸåˆ™ï¼š
- ä¿å®ˆè°¨æ…ï¼Œä¸ç¡®å®šæ—¶é€‰æ‹© HOLD
- ä¿¡å·å¼ºåº¦ï¼ˆconfidence_scoreï¼‰è¦å¦‚å®åæ˜ åˆ†æçš„ç¡®å®šæ€§
- å¿…é¡»åŸºäºæä¾›çš„æ•°æ®ï¼Œä¸è¦è‡†æµ‹

è¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºï¼ŒåŒ…å« signal, confidence_score, reason ä¸‰ä¸ªå­—æ®µã€‚"""

    def __init__(self, 
                 data_fetcher: AlpacaDataFetcher,
                 cache: Optional[TradingCache] = None,
                 use_cache: bool = True,
                 system_prompt: Optional[str] = None,
                 model: str = GEMINI_MODEL,
                 temperature: float = 0.2,
                 delay_seconds: int = 2):
        """
        åˆå§‹åŒ– Gemini äº¤æ˜“ç­–ç•¥ã€‚
        
        Args:
            data_fetcher: AlpacaDataFetcher å®ä¾‹
            cache: TradingCache å®ä¾‹ï¼ˆå¯é€‰ï¼‰
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            system_prompt: è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯
            model: Gemini æ¨¡å‹åç§°
            temperature: ç”Ÿæˆæ¸©åº¦ï¼ˆ0-1ï¼Œè¶Šä½è¶Šç¡®å®šï¼‰
            delay_seconds: API è°ƒç”¨é—´éš”ï¼ˆé¿å…é€Ÿç‡é™åˆ¶ï¼‰
        """
        super().__init__(data_fetcher) # è°ƒç”¨åŸºç±»æ„é€ å‡½æ•°
        self.cache = cache
        self.use_cache = use_cache and cache is not None
        self.system_prompt = system_prompt or self.DEFAULT_SYSTEM_PROMPT
        self.model = model
        self.temperature = temperature
        self.delay_seconds = delay_seconds
        
        # åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯
        try:
            self.client = genai.Client()
            print(f"âœ… GeminiStrategy åˆå§‹åŒ–å®Œæˆã€‚")
            print(f"   æ¨¡å‹: {model}, æ¸©åº¦: {temperature}, ç¼“å­˜: {'å¯ç”¨' if self.use_cache else 'ç¦ç”¨'}")
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯å¤±è´¥ï¼š{e}")
            print("   è¯·æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ GEMINI_API_KEY æ˜¯å¦è®¾ç½®æ­£ç¡®ã€‚")
            self.client = None
    
    def _format_data_for_llm(self, df: pd.DataFrame, ticker: str) -> str:
        """
        å°†æŠ€æœ¯æŒ‡æ ‡æ•°æ®æ ¼å¼åŒ–ä¸º LLM å‹å¥½çš„æ–‡æœ¬ã€‚
        
        Args:
            df: åŒ…å«æŠ€æœ¯æŒ‡æ ‡çš„ DataFrame
            ticker: è‚¡ç¥¨ä»£ç 
            
        Returns:
            str: æ ¼å¼åŒ–çš„ Markdown è¡¨æ ¼æ–‡æœ¬
        """
        if df.empty:
            return "æ²¡æœ‰å¯ç”¨çš„å¸‚åœºæ•°æ®ã€‚"
        
        # é€‰æ‹©æœ€è¿‘ 10 ä¸ªæ•°æ®ç‚¹
        df_display = df.tail(10).copy()
        
        # æ ¼å¼åŒ–æ—¶é—´ç´¢å¼•
        if hasattr(df_display.index, 'strftime'):
            df_display.index = df_display.index.strftime('%H:%M')
        
        # é€‰æ‹©éœ€è¦æ˜¾ç¤ºçš„åˆ—
        cols_to_show = []
        for col in ['close', 'volume', 'SMA', 'BB_UPPER', 'BB_LOWER', 'RSI']:
            if col in df_display.columns:
                cols_to_show.append(col)
        
        df_display = df_display[cols_to_show]
        
        # é‡å‘½ååˆ—ä¸ºæ›´å‹å¥½çš„åç§°
        col_mapping = {
            'close': 'Close',
            'volume': 'Volume',
            'SMA': 'SMA_20',
            'BB_UPPER': 'BB_Upper',
            'BB_LOWER': 'BB_Lower',
            'RSI': 'RSI_14'
        }
        df_display.rename(columns=col_mapping, inplace=True)
        
        # æ ¼å¼åŒ–æ•°å€¼
        for col in df_display.columns:
            if col != 'Volume':
                df_display[col] = df_display[col].round(2)
        
        # è½¬æ¢ä¸º Markdown
        markdown_table = df_display.to_markdown()
        
        return f"### {ticker} æŠ€æœ¯æŒ‡æ ‡æ•°æ®ï¼ˆæœ€è¿‘10ä¸ªæ—¶é—´ç‚¹ï¼‰\n\n{markdown_table}"
    
    def _calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆå¸ƒæ—å¸¦å’Œ RSIï¼‰ã€‚
        
        Args:
            df: åŸå§‹ OHLCV DataFrame
            
        Returns:
            pd.DataFrame: æ·»åŠ äº†æŠ€æœ¯æŒ‡æ ‡çš„ DataFrame
        """
        df = df.copy()
        
        # å¸ƒæ—å¸¦ (20 period, 2 std dev)
        df['SMA'] = df['close'].rolling(window=20).mean()
        df['STD'] = df['close'].rolling(window=20).std()
        df['BB_UPPER'] = df['SMA'] + (df['STD'] * 2)
        df['BB_LOWER'] = df['SMA'] - (df['STD'] * 2)
        
        # RSI (14 period)
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        RS = gain / loss
        df['RSI'] = 100 - (100 / (1 + RS))
        
        # åˆ é™¤è®¡ç®—äº§ç”Ÿçš„ä¸­é—´åˆ—
        df.drop(['STD'], axis=1, inplace=True, errors='ignore')
        
        return df
    
    def _generate_cache_key(self, ticker: str, timestamp: datetime, formatted_data: str) -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®ã€‚
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            timestamp: æ—¶é—´æˆ³
            formatted_data: æ ¼å¼åŒ–åçš„æ•°æ®æ–‡æœ¬
            
        Returns:
            str: SHA256 å“ˆå¸Œå€¼ä½œä¸ºç¼“å­˜é”®
        """
        # ç»„åˆæ‰€æœ‰è¾“å…¥æ¥ç”Ÿæˆå”¯ä¸€é”®
        key_input = f"{ticker}|{timestamp.isoformat()}|{formatted_data}"
        return hashlib.sha256(key_input.encode('utf-8')).hexdigest()
    
    def _call_gemini_api(self, user_prompt: str) -> Dict:
        """
        è°ƒç”¨ Gemini API è·å–äº¤æ˜“ä¿¡å·ã€‚
        
        Args:
            user_prompt: ç”¨æˆ·æç¤ºè¯ï¼ˆåŒ…å«æ ¼å¼åŒ–çš„å¸‚åœºæ•°æ®ï¼‰
            
        Returns:
            Dict: åŒ…å« signal, confidence_score, reason çš„å­—å…¸
        """
        if not self.client:
            return {
                "signal": "HOLD",
                "confidence_score": 0,
                "reason": "Gemini client not initialized"
            }
        
        print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨ Gemini API ({self.model})...")
        
        # ç­‰å¾…ä»¥é¿å…é€Ÿç‡é™åˆ¶
        if self.delay_seconds > 0:
            time.sleep(self.delay_seconds)
        
        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=[
                    {"role": "user", "parts": [{"text": self.system_prompt}]},
                    {"role": "user", "parts": [{"text": user_prompt}]}
                ],
                config=genai.types.GenerateContentConfig(
                    response_mime_type="application/json",
                    response_schema=TradingSignal,
                    temperature=self.temperature
                )
            )
            
            if not response.text:
                raise Exception("Gemini API è¿”å›äº†ç©ºå“åº”ã€‚")
            
            result = json.loads(response.text)
            print(f"âœ… Gemini åˆ†æå®Œæˆã€‚ä¿¡å·: {result['signal']}, ç½®ä¿¡åº¦: {result['confidence_score']}/10")
            
            return result
            
        except Exception as e:
            print(f"âŒ è°ƒç”¨ Gemini API å¤±è´¥: {e}")
            return {
                "signal": "HOLD",
                "confidence_score": 0,
                "reason": f"API Error: {str(e)}"
            }
    
    def get_signal(self,
                   ticker: str,
                   end_dt: Optional[datetime] = None,
                   lookback_minutes: int = 120,
                   timeframe: TimeFrame = TimeFrame(5, TimeFrameUnit.Minute)) -> Tuple[Dict, float]:
        """
        è·å–æŒ‡å®šæ—¶é—´ç‚¹çš„ AI äº¤æ˜“ä¿¡å·ã€‚
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            end_dt: ç»“æŸæ—¶é—´ï¼ˆé»˜è®¤ä¸ºå½“å‰æ—¶é—´ï¼‰
            lookback_minutes: å›æº¯æ—¶é—´é•¿åº¦ï¼ˆåˆ†é’Ÿï¼‰
            timeframe: Kçº¿æ—¶é—´æ¡†æ¶
            
        Returns:
            Tuple[signal_dict, current_price]:
                - signal_dict: åŒ…å« signal, confidence_score, reason çš„å­—å…¸
                - current_price: å½“å‰ä»·æ ¼
        """
        # 1. è·å–åŸå§‹æ•°æ®
        df = self.data_fetcher.get_latest_bars(
            ticker=ticker,
            lookback_minutes=lookback_minutes,
            timeframe=timeframe,
            end_dt=end_dt
        )
        
        if df.empty:
            print(f"âŒ æ— æ³•è·å– {ticker} çš„æ•°æ®ã€‚")
            return {"signal": "HOLD", "confidence_score": 0, "reason": "No data"}, 0.0
        
        # 2. è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        df = self._calculate_technical_indicators(df)
        df = df.dropna()
        
        if df.empty:
            print(f"âŒ è®¡ç®—æŠ€æœ¯æŒ‡æ ‡åæ•°æ®ä¸è¶³ã€‚")
            return {"signal": "HOLD", "confidence_score": 0, "reason": "Insufficient data"}, 0.0
        
        # 3. è·å–å½“å‰ä»·æ ¼
        current_price = df['close'].iloc[-1]
        
        # 4. æ ¼å¼åŒ–æ•°æ®ç»™ LLM
        formatted_data = self._format_data_for_llm(df, ticker)
        
        # 5. æ£€æŸ¥ç¼“å­˜
        timestamp_for_display = end_dt if end_dt else datetime.now(timezone.utc)
        
        if self.use_cache:
            cache_key = self._generate_cache_key(ticker, timestamp_for_display, formatted_data)
            cached_result = self.cache.get(cache_key)
            
            if cached_result:
                print(f"âœ… ç¼“å­˜å‘½ä¸­ï¼è¿”å›ç¼“å­˜çš„ Gemini åˆ†æç»“æœã€‚")
                return cached_result, current_price
        
        # 6. æ„é€ ç”¨æˆ·æç¤ºè¯
        user_prompt = f"""è¯·åˆ†æä»¥ä¸‹ {ticker} çš„å¸‚åœºæ•°æ®å¹¶ç»™å‡ºäº¤æ˜“å»ºè®®ã€‚

å½“å‰æ—¶é—´: {timestamp_for_display.strftime('%Y-%m-%d %H:%M UTC')}

{formatted_data}

è¯·åŸºäºä»¥ä¸ŠæŠ€æœ¯æŒ‡æ ‡ï¼Œç»™å‡ºä½ çš„äº¤æ˜“å»ºè®®ã€‚"""
        
        # 7. è°ƒç”¨ Gemini API
        signal_result = self._call_gemini_api(user_prompt)
        
        # 8. ä¿å­˜åˆ°ç¼“å­˜
        if self.use_cache and (signal_result.get('signal') != 'HOLD' or signal_result.get('confidence_score', 0) > 0):
            # åªæœ‰å½“ signal_result åŒ…å«æœ‰æ•ˆä¿¡å·æ—¶æ‰ä¿å­˜
            self.cache.add(cache_key, signal_result)
        
        # 9. æ‰“å°ä¿¡å·ä¿¡æ¯
        print(f"\nğŸ¯ [{timestamp_for_display.strftime('%Y-%m-%d %H:%M UTC')}] {ticker} Gemini åˆ†æ:")
        print(f"   ä»·æ ¼: ${current_price:.2f}")
        print(f"   ä¿¡å·: {signal_result.get('signal', 'N/A')} (ç½®ä¿¡åº¦: {signal_result.get('confidence_score', 0)}/10)")
        print(f"   åŸå› : {signal_result.get('reason', 'N/A')}")
        
        return signal_result, current_price


# æµ‹è¯•ç”¨ä¾‹
if __name__ == '__main__':
    from datetime import datetime, timezone
    
    # éœ€è¦å‡è®¾ AlpacaDataFetcher å’Œ TradingCache å­˜åœ¨
    class MockDataFetcher:
        def get_latest_bars(self, ticker, lookback_minutes, timeframe, end_dt):
            print(f"Mocking data fetch for {ticker}...")
            # æ„é€ æ¨¡æ‹Ÿæ•°æ®ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„è¡Œè¿›è¡ŒæŒ‡æ ‡è®¡ç®—
            data = {
                'open': [100, 101, 99, 98, 97, 96, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110],
                'high': [101, 102, 100, 99, 98, 97, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111],
                'low': [99, 100, 98, 97, 96, 95, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109],
                'close': [100.5, 101.5, 99.5, 98.5, 97.5, 96.5, 95.5, 96.5, 97.5, 98.5, 99.5, 100.5, 101.5, 102.5, 103.5, 104.5, 105.5, 106.5, 107.5, 108.5, 109.5, 110.5],
                'volume': [1000] * 22
            }
            # åˆ›å»ºä¸€ä¸ªæ—¶é—´ç´¢å¼•
            index = pd.to_datetime(pd.date_range(end=datetime.now(timezone.utc), periods=len(data['close']), freq='5min'), utc=True)
            return pd.DataFrame(data, index=index)
        
    class MockTradingCache:
        def __init__(self, filename):
            self.data = {}
            self.filename = filename
        def get(self, key):
            return self.data.get(key)
        def add(self, key, value):
            self.data[key] = value
        def save(self):
            print(f"Saving mock cache to {self.filename}")
            
    fetcher = MockDataFetcher()
    cache = MockTradingCache('gemini_test_cache.json')
    
    # æ¨¡æ‹Ÿ genai.Client ä»¥é¿å…çœŸæ­£çš„ API è°ƒç”¨
    class MockGenaiClient:
        def __init__(self):
            class MockModels:
                def generate_content(self, model, contents, config):
                    class MockResponse:
                        def __init__(self, text):
                            self.text = text
                    
                    # æ£€æŸ¥ prompt å†³å®šè¿”å› BUY æˆ– SELL
                    if "è·Œç ´å¸ƒæ—å¸¦" in contents[1]['parts'][0]['text']:
                        signal_text = '{"signal": "BUY", "confidence_score": 8, "reason": "ä»·æ ¼å·²è§¦åŠå¸ƒæ—å¸¦ä¸‹è½¨ï¼Œä¸”RSIå¤„äºè¶…å–åŒºåŸŸï¼Œé¢„è®¡çŸ­æœŸå†…å°†åå¼¹ã€‚"}'
                    elif "çªç ´å¸ƒæ—å¸¦" in contents[1]['parts'][0]['text']:
                        signal_text = '{"signal": "SELL", "confidence_score": 7, "reason": "ä»·æ ¼å·²çªç ´å¸ƒæ—å¸¦ä¸Šè½¨ï¼Œå‡ºç°è¶…ä¹°ä¿¡å·ï¼Œå»ºè®®è·åˆ©äº†ç»“ã€‚"}'
                    else:
                        signal_text = '{"signal": "HOLD", "confidence_score": 5, "reason": "ä»·æ ¼åœ¨å‡çº¿é™„è¿‘ç›˜æ•´ï¼Œç¼ºä¹æ˜ç¡®æ–¹å‘ã€‚"}'
                        
                    return MockResponse(signal_text)
            self.models = MockModels()

    # æ›¿æ¢å®é™…çš„ genai.Client
    strategy = GeminiStrategy(
        data_fetcher=fetcher,
        cache=cache,
        use_cache=True,
        temperature=0.2,
        delay_seconds=0 # ç§»é™¤å»¶è¿Ÿ
    )
    strategy.client = MockGenaiClient() # ä½¿ç”¨ Mock Client
    
    # æµ‹è¯•è·å–ä¿¡å·
    print("\n" + "="*60)
    print("æµ‹è¯• GeminiStrategy - AI é©±åŠ¨çš„äº¤æ˜“å†³ç­– (ä½¿ç”¨ Mock)")
    print("="*60)
    
    signal_dict, price = strategy.get_signal(
        ticker="TSLA",
        lookback_minutes=120,
        timeframe=TimeFrame(5, TimeFrameUnit.Minute)
    )
    
    print(f"\næœ€ç»ˆè¾“å‡º:")
    print(f"  ä¿¡å·: {signal_dict.get('signal')}")
    print(f"  ç½®ä¿¡åº¦: {signal_dict.get('confidence_score')}/10")
    print(f"  åŸå› : {signal_dict.get('reason')}")
    print(f"  å½“å‰ä»·æ ¼: ${price:.2f}")
    
    # ä¿å­˜ç¼“å­˜
    if len(cache.data) > 0:
        cache.save()